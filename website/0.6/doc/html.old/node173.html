<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">

<!--Converted with LaTeX2HTML 2002-2-1 (1.70)
original version by:  Nikos Drakos, CBLU, University of Leeds
* revised and updated by:  Marcus Hennecke, Ross Moore, Herb Swan
* with significant contributions from:
  Jens Lippmann, Marek Rouchal, Martin Wilck and others -->
<HTML>
<HEAD>
<TITLE>7.2 The Probability Density Function</TITLE>
<META NAME="description" CONTENT="7.2 The Probability Density Function">
<META NAME="keywords" CONTENT="pyxplot">
<META NAME="resource-type" CONTENT="document">
<META NAME="distribution" CONTENT="global">

<META NAME="Generator" CONTENT="LaTeX2HTML v2002-2-1">
<META HTTP-EQUIV="Content-Style-Type" CONTENT="text/css">

<LINK REL="STYLESHEET" HREF="pyxplot.css">

<LINK REL="next" HREF="node174.html">
<LINK REL="previous" HREF="node172.html">
<LINK REL="up" HREF="node171.html">
<LINK REL="next" HREF="node174.html">
</HEAD>

<BODY >

<DIV CLASS="navigation"><!--Navigation Panel-->
<A NAME="tex2html3058"
  HREF="node174.html">
<IMG WIDTH="37" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="next" SRC="next.png"></A> 
<A NAME="tex2html3052"
  HREF="node171.html">
<IMG WIDTH="26" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="up" SRC="up.png"></A> 
<A NAME="tex2html3046"
  HREF="node172.html">
<IMG WIDTH="63" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="previous" SRC="prev.png"></A> 
<A NAME="tex2html3054"
  HREF="node1.html">
<IMG WIDTH="65" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="contents" SRC="contents.png"></A> 
<A NAME="tex2html3056"
  HREF="node179.html">
<IMG WIDTH="43" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="index" SRC="index.png"></A> 
<BR>
<B> Next:</B> <A NAME="tex2html3059"
  HREF="node174.html">7.3 Estimating the Error</A>
<B> Up:</B> <A NAME="tex2html3053"
  HREF="node171.html">7. The fit Command:</A>
<B> Previous:</B> <A NAME="tex2html3047"
  HREF="node172.html">7.1 Notation</A>
 &nbsp; <B>  <A NAME="tex2html3055"
  HREF="node1.html">Contents</A></B> 
 &nbsp; <B>  <A NAME="tex2html3057"
  HREF="node179.html">Index</A></B> 
<BR>
<BR></DIV>
<!--End of Navigation Panel-->

<H1><A NAME="SECTION00820000000000000000"></A>
<A NAME="bayes_pdf"></A>
<BR>
<SPAN CLASS="arabic">7</SPAN>.<SPAN CLASS="arabic">2</SPAN> The Probability Density Function
</H1>

<P>
Bayes' Theorem states that:

<P>
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
\mathrm{P}\left( \mathbf{u} | \left\{ \mathbf{x}_i, f_i, \sigma_i \right\} \right) =
\frac{
\mathrm{P}\left( \left\{f_i \right\} | \mathbf{u}, \left\{ \mathbf{x}_i, \sigma_i \right\} \right)
\mathrm{P}\left( \mathbf{u} | \left\{ \mathbf{x}_i, \sigma_i \right\} \right)
}{
\mathrm{P}\left( \left\{f_i \right\} | \left\{ \mathbf{x}_i, \sigma_i \right\} \right)
}
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="406" HEIGHT="58" ALIGN="MIDDLE" BORDER="0"
 SRC="img113.png"
 ALT="$\displaystyle \mathrm{P}\left( \mathbf{u} \vert \left\{ \mathbf{x}_i, f_i, \sig...
...t( \left\{f_i \right\} \vert \left\{ \mathbf{x}_i, \sigma_i \right\} \right) }$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">7</SPAN>.<SPAN CLASS="arabic">1</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
Since we are only seeking to maximise the quantity on the left, and the
denominator, termed the Bayesian <SPAN  CLASS="textit">evidence</SPAN>, is independent of
<!-- MATH
 $\mathbf{u}$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="15" HEIGHT="15" ALIGN="BOTTOM" BORDER="0"
 SRC="img111.png"
 ALT="$ \mathbf{u}$"></SPAN>, we can neglect it and replace the equality sign with a
proportionality sign.  Furthermore, if we assume a uniform prior, that is, we
assume that we have no prior knowledge to bias us towards certain more favoured
values of <!-- MATH
 $\mathbf{u}$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="15" HEIGHT="15" ALIGN="BOTTOM" BORDER="0"
 SRC="img111.png"
 ALT="$ \mathbf{u}$"></SPAN>, then <!-- MATH
 $\mathrm{P}\left( \mathbf{u} \right)$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="44" HEIGHT="35" ALIGN="MIDDLE" BORDER="0"
 SRC="img114.png"
 ALT="$ \mathrm{P}\left( \mathbf{u} \right)$"></SPAN> is also a
constant which can be neglected. We conclude that maximising <!-- MATH
 $\mathrm{P}\left(
\mathbf{u} | \left\{ \mathbf{x}_i, f_i, \sigma_i \right\} \right)$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="130" HEIGHT="35" ALIGN="MIDDLE" BORDER="0"
 SRC="img112.png"
 ALT="$ \mathrm{P}\left( \mathbf{u} \vert \left\{ \mathbf{x}_i, f_i, \sigma_i \right\} \right)$"></SPAN> is
equivalent to maximising <!-- MATH
 $\mathrm{P}\left( \left\{f_i \right\} | \mathbf{u},
\left\{ \mathbf{x}_i, \sigma_i \right\} \right)$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="147" HEIGHT="35" ALIGN="MIDDLE" BORDER="0"
 SRC="img115.png"
 ALT="$ \mathrm{P}\left( \left\{f_i \right\} \vert \mathbf{u},
\left\{ \mathbf{x}_i, \sigma_i \right\} \right)$"></SPAN>.

<P>
Since we are assuming <SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="33" ALIGN="MIDDLE" BORDER="0"
 SRC="img106.png"
 ALT="$ f_i$"></SPAN> to be Gaussian-distributed observations of the true
function <SPAN CLASS="MATH"><IMG
 WIDTH="28" HEIGHT="35" ALIGN="MIDDLE" BORDER="0"
 SRC="img97.png"
 ALT="$ f()$"></SPAN>, this latter probability can be written as a product of
<!-- MATH
 $n_\mathrm{d}$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="23" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img102.png"
 ALT="$ n_\mathrm{d}$"></SPAN> Gaussian distributions:

<P>
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
\mathrm{P}\left( \left\{f_i \right\} | \mathbf{u}, \left\{ \mathbf{x}_i, \sigma_i \right\} \right)
=
\prod_{i=0}^{n_\mathrm{d}-1} \frac{1}{\sigma_i\sqrt{2\pi}} \exp \left(
\frac{
-\left[f_i - f_\mathbf{u}(\mathbf{x}_i)\right]^2
}{
2 \sigma_i^2
} \right)
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="439" HEIGHT="73" ALIGN="MIDDLE" BORDER="0"
 SRC="img116.png"
 ALT="$\displaystyle \mathrm{P}\left( \left\{f_i \right\} \vert \mathbf{u}, \left\{ \m...
... -\left[f_i - f_\mathbf{u}(\mathbf{x}_i)\right]^2 }{ 2 \sigma_i^2 } \right)$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">7</SPAN>.<SPAN CLASS="arabic">2</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
The product in this equation can be converted into a more computationally
workable sum by taking the logarithm of both sides. Since logarithms are
monotonically increasing functions, maximising a probability is equivalent to
maximising its logarithm. We may write the logarithm <SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="15" ALIGN="BOTTOM" BORDER="0"
 SRC="img117.png"
 ALT="$ L$"></SPAN> of <!-- MATH
 $\mathrm{P}\left(
\mathbf{u} | \left\{ \mathbf{x}_i, f_i, \sigma_i \right\} \right)$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="130" HEIGHT="35" ALIGN="MIDDLE" BORDER="0"
 SRC="img112.png"
 ALT="$ \mathrm{P}\left( \mathbf{u} \vert \left\{ \mathbf{x}_i, f_i, \sigma_i \right\} \right)$"></SPAN> as:

<P>
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
L = \sum_{i=0}^{n_\mathrm{d}-1}
\left( \frac{
-\left[f_i - f_\mathbf{u}(\mathbf{x}_i)\right]^2
}{
2 \sigma_i^2
} \right) + k
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="254" HEIGHT="73" ALIGN="MIDDLE" BORDER="0"
 SRC="img118.png"
 ALT="$\displaystyle L = \sum_{i=0}^{n_\mathrm{d}-1} \left( \frac{ -\left[f_i - f_\mathbf{u}(\mathbf{x}_i)\right]^2 }{ 2 \sigma_i^2 } \right) + k$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">7</SPAN>.<SPAN CLASS="arabic">3</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
where <SPAN CLASS="MATH"><IMG
 WIDTH="14" HEIGHT="15" ALIGN="BOTTOM" BORDER="0"
 SRC="img119.png"
 ALT="$ k$"></SPAN> is some constant which does not affect the maximisation
process. It is this quantity, the familiar sum-of-square-residuals, that we
numerically maximise to find our best-fitting set of parameters, which I shall
refer to from here on as <!-- MATH
 $\mathbf{u}^0$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="23" HEIGHT="18" ALIGN="BOTTOM" BORDER="0"
 SRC="img120.png"
 ALT="$ \mathbf{u}^0$"></SPAN>.

<P>

<DIV CLASS="navigation"><HR>
<!--Navigation Panel-->
<A NAME="tex2html3058"
  HREF="node174.html">
<IMG WIDTH="37" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="next" SRC="next.png"></A> 
<A NAME="tex2html3052"
  HREF="node171.html">
<IMG WIDTH="26" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="up" SRC="up.png"></A> 
<A NAME="tex2html3046"
  HREF="node172.html">
<IMG WIDTH="63" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="previous" SRC="prev.png"></A> 
<A NAME="tex2html3054"
  HREF="node1.html">
<IMG WIDTH="65" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="contents" SRC="contents.png"></A> 
<A NAME="tex2html3056"
  HREF="node179.html">
<IMG WIDTH="43" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="index" SRC="index.png"></A> 
<BR>
<B> Next:</B> <A NAME="tex2html3059"
  HREF="node174.html">7.3 Estimating the Error</A>
<B> Up:</B> <A NAME="tex2html3053"
  HREF="node171.html">7. The fit Command:</A>
<B> Previous:</B> <A NAME="tex2html3047"
  HREF="node172.html">7.1 Notation</A>
 &nbsp; <B>  <A NAME="tex2html3055"
  HREF="node1.html">Contents</A></B> 
 &nbsp; <B>  <A NAME="tex2html3057"
  HREF="node179.html">Index</A></B> </DIV>
<!--End of Navigation Panel-->
<ADDRESS>
Dominic Ford, 24 November 2006
</ADDRESS>
</BODY>
</HTML>
